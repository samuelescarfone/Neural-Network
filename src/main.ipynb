{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural-Network With Numpy and Math\n",
    "Goal for this project is to gain an understanding of the inner workings of a neural network. To accomplish we will just using Numpy, without using any pre-built frameworks and the MNIST dataset from Kaggle.  \n",
    "We will then test the model against a keras model to compare effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"../data/digit-recognizer/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the dataset to a NumPy array and shuffled it to remove ordering bias.**\n",
    "\n",
    "*Split the data into:*\n",
    "\n",
    "Training set (all but first 1000 examples)\n",
    "\n",
    "Validation set (first 1000 examples)\n",
    "\n",
    "Transposed the data so each column represents one image.\n",
    "\n",
    "Separated labels (Y) from pixel data (X).\n",
    "\n",
    "Normalized pixel values by dividing by 255 to scale them to [0, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape \n",
    "\n",
    "np.random.shuffle(data) #shuffle to remove label bias\n",
    "\n",
    "val_set = data[0:1000].T # First 1000 examples are validation set, transpose each so column is an example\n",
    "y_dev = val_set[0] #labels for 1000 validation examples (first row)\n",
    "x_dev = val_set[1:n] #gets 784 pixel vals for each image (rows 1 to 784)\n",
    "x_dev = x_dev/255 #Normalize pixel vals from 0-255 -> 0-1\n",
    "\n",
    "dat_train = data[1000:m].T #training set\n",
    "y_train = dat_train[0]\n",
    "x_train = dat_train[1:n]\n",
    "x_train = x_train / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN will have a simple two‑layer architecture.  \n",
    "Input layer $a^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28×28 input image. A hidden layer $a^{[1]}$ will have 10 units with **ReLU** activation, and finally our output layer $a^{[2]}$ will have 10 units corresponding to the ten digit classes with **softmax** activation.\n",
    "\n",
    "\n",
    "\n",
    "### **Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$  \n",
    "*Multiply the input matrix $X$ by the first‑layer weights $W^{[1]}$ and add the bias $b^{[1]}$ to get raw scores for each hidden neuron.*\n",
    "\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$  \n",
    "*Apply the ReLU function element‑wise: values $\\le 0$ become 0, positives stay the same.  \n",
    "The result $A^{[1]}$ is the hidden layer’s output.*\n",
    "\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$  \n",
    "*Feed the hidden activations into the second weight matrix, add the bias, and get one raw score per digit class.*\n",
    "\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$  \n",
    "*Softmax turns those scores into probabilities that sum to 1 for each image (column).*\n",
    "\n",
    "\n",
    "### **Backward propagation**\n",
    "\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$  \n",
    "*Difference between predicted probabilities and the true one‑hot labels.*\n",
    "\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$  \n",
    "*Gradient of the loss with respect to second‑layer weights (average over $m$ examples).*\n",
    "\n",
    "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$  \n",
    "*Gradient for the second‑layer biases.*\n",
    "\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$  \n",
    "*Back‑propagate the error to the hidden layer and gate it with ReLU’s derivative  \n",
    "($g^{[1]\\prime}(z)=1$ where $z>0$, else 0).*\n",
    "\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$  \n",
    "*Gradient of the loss with respect to first‑layer weights.*\n",
    "\n",
    "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$  \n",
    "*Gradient for the first‑layer biases.*\n",
    "\n",
    "\n",
    "### **Parameter updates**  (Gradient Descent)\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$  \n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$  \n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$  \n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$  \n",
    "\n",
    "*Subtract a small fraction ($\\alpha$ = learning rate) of each gradient to nudge the parameters toward lower error.*\n",
    "\n",
    "\n",
    "### **Vars and shapes**\n",
    "\n",
    "Forward prop  \n",
    "\n",
    "- $A^{[0]} = X$: 784 × m  \n",
    "- $Z^{[1]} \\sim A^{[1]}$: 10 × m  \n",
    "- $W^{[1]}$: 10 × 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)  \n",
    "- $B^{[1]}$: 10 × 1  \n",
    "- $Z^{[2]} \\sim A^{[2]}$: 10 × m  \n",
    "- $W^{[1]}$: 10 × 10 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)  \n",
    "- $B^{[2]}$: 10 × 1  \n",
    "\n",
    "Backprop  \n",
    "\n",
    "- $dZ^{[2]}$: 10 × m ($\\sim A^{[2]}$)  \n",
    "- $dW^{[2]}$: 10 × 10  \n",
    "- $dB^{[2]}$: 10 × 1  \n",
    "- $dZ^{[1]}$: 10 × m ($\\sim A^{[1]}$)  \n",
    "- $dW^{[1]}$: 10 × 10  \n",
    "- $dB^{[1]}$: 10 × 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup weights and biases\n",
    "def init_params():\n",
    "    w1 = np.random.randn(10, 784) * np.sqrt(2/784) \n",
    "    b1 = np.zeros((10,1)) \n",
    "    w2 = np.random.randn(10, 10)  * np.sqrt(2/10)\n",
    "    b2 = np.zeros((10,1))\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "#Sets every negative element to zero, keeps positives\n",
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def softmax(z):\n",
    "    expZ = np.exp(z - np.max(z, axis=0, keepdims=True))  \n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "def forwardPropogation(w1,b1,w2,b2,x):\n",
    "    z1 = w1.dot(x)+b1 \n",
    "    a1 = relu(z1)\n",
    "    z2 = w2.dot(a1)+b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def derivRelu(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "def one_hot(y):\n",
    "    oneHotY= np.zeros((y.size, y.max()+1))\n",
    "    oneHotY[np.arange(y.size), y] = 1\n",
    "    oneHotY = oneHotY.T\n",
    "    return oneHotY\n",
    "\n",
    "def backward_propogation(z1,a1,z2,a2,w1,w2,x,y):\n",
    "    oneHotY = one_hot(y)\n",
    "    dz2 = a2 - oneHotY\n",
    "    dw2 = (1 / m) * dz2.dot(a1.T)\n",
    "    db2 = (1 / m) * np.sum(dz2, axis=1, keepdims=True)\n",
    "\n",
    "    dz1 = w2.T.dot(dz2) * derivRelu(z1)\n",
    "    dw1 = (1 / m) * dz1.dot(x.T)\n",
    "    db1 = (1 / m) * np.sum(dz1, axis=1, keepdims=True)\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
    "    w1 = w1-alpha *dw1\n",
    "    b1 = b1- alpha *db1\n",
    "    w2 = w2 - alpha *dw2\n",
    "    b2 = b2 - alpha *db2\n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2,0)\n",
    "\n",
    "def get_accuracy(pred, y):\n",
    "    print(pred, y)\n",
    "    return np.sum(pred == y)/y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forwardPropogation(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_propogation(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[2 9 9 ... 2 2 9] [4 1 1 ... 4 7 1]\n",
      "0.0581219512195122\n",
      "Iteration:  10\n",
      "[2 1 9 ... 2 7 1] [4 1 1 ... 4 7 1]\n",
      "0.2852195121951219\n",
      "Iteration:  20\n",
      "[9 1 1 ... 2 7 1] [4 1 1 ... 4 7 1]\n",
      "0.43921951219512195\n",
      "Iteration:  30\n",
      "[9 1 1 ... 2 7 1] [4 1 1 ... 4 7 1]\n",
      "0.5317317073170732\n",
      "Iteration:  40\n",
      "[9 1 1 ... 2 7 1] [4 1 1 ... 4 7 1]\n",
      "0.5978536585365853\n",
      "Iteration:  50\n",
      "[9 1 1 ... 2 7 1] [4 1 1 ... 4 7 1]\n",
      "0.6833902439024391\n"
     ]
    }
   ],
   "source": [
    "# Output is: Iteration | [Predictions] | [true labels] | Accuracy\n",
    "W1, b1, W2, b2 = gradient_descent(x_train, y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forwardPropogation(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = x_train[:, index, None]\n",
    "    prediction = make_predictions(x_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [5]\n",
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(0, W1, b1, W2, b2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create a model using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainK = x_train.T\n",
    "x_devK = x_dev.T\n",
    "y_trainK= tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_devK= tf.keras.utils.to_categorical(y_dev,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = models.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64,  activation=\"relu\"),\n",
    "    layers.Dense(10,  activation=\"softmax\")\n",
    "])\n",
    "keras_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "641/641 - 1s - 2ms/step - accuracy: 0.9099 - loss: 0.3166 - val_accuracy: 0.9560 - val_loss: 0.1487\n",
      "Epoch 2/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9610 - loss: 0.1327 - val_accuracy: 0.9690 - val_loss: 0.1078\n",
      "Epoch 3/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9718 - loss: 0.0915 - val_accuracy: 0.9760 - val_loss: 0.0857\n",
      "Epoch 4/20\n",
      "641/641 - 1s - 2ms/step - accuracy: 0.9794 - loss: 0.0658 - val_accuracy: 0.9780 - val_loss: 0.0804\n",
      "Epoch 5/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9836 - loss: 0.0520 - val_accuracy: 0.9790 - val_loss: 0.0783\n",
      "Epoch 6/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9876 - loss: 0.0398 - val_accuracy: 0.9820 - val_loss: 0.0740\n",
      "Epoch 7/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9895 - loss: 0.0326 - val_accuracy: 0.9810 - val_loss: 0.0758\n",
      "Epoch 8/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9917 - loss: 0.0260 - val_accuracy: 0.9650 - val_loss: 0.1284\n",
      "Epoch 9/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9935 - loss: 0.0208 - val_accuracy: 0.9780 - val_loss: 0.0842\n",
      "Epoch 10/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.9760 - val_loss: 0.0899\n",
      "Epoch 11/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9953 - loss: 0.0151 - val_accuracy: 0.9800 - val_loss: 0.0886\n",
      "Epoch 12/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9949 - loss: 0.0154 - val_accuracy: 0.9740 - val_loss: 0.1115\n",
      "Epoch 13/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9956 - loss: 0.0134 - val_accuracy: 0.9720 - val_loss: 0.1020\n",
      "Epoch 14/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9967 - loss: 0.0106 - val_accuracy: 0.9790 - val_loss: 0.0931\n",
      "Epoch 15/20\n",
      "641/641 - 1s - 1ms/step - accuracy: 0.9969 - loss: 0.0101 - val_accuracy: 0.9660 - val_loss: 0.1670\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_trainK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trainK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_devK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_devK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(\n",
    "    x_trainK, y_trainK,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_devK, y_devK),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = keras_model.evaluate(x_devK, y_devK, verbose=0)\n",
    "print(f\"Keras model accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets see how they perform side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction_keras(index, model):\n",
    "    img_vec = x_train[:, index, None]\n",
    "    label= y_train[index]\n",
    "\n",
    "    # Keras prediction\n",
    "    predK = np.argmax(model.predict(img_vec.T, verbose=0))\n",
    "\n",
    "    #manual network prediction\n",
    "    predMan = make_predictions(img_vec, W1, b1, W2, b2)[0]\n",
    "\n",
    "    print(f\"Keras prediction: {predK}\")\n",
    "    print(f\"Manual prediction: {predMan}\")\n",
    "    print(f\"Label: {label}\")\n",
    "\n",
    "    plt.gray()\n",
    "    plt.imshow((img_vec.reshape(28,28)*255), interpolation=\"nearest\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras prediction: 7\n",
      "Manual prediction: 7\n",
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction_keras(9, keras_model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
